{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a484cdd3",
   "metadata": {},
   "source": [
    "## Phase 1: Indexing (One-time Setup)\n",
    "\n",
    "This phase processes your PDF documents and creates the searchable vector database.\n",
    "Run these cells once to index your documents, then use Phase 2 for queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b45063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400 pages from PDFs\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_core.documents import Document\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"../Data/\"\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "OLLAMA_EMBEDDING_MODEL = \"mxbai-embed-large:335m\"\n",
    "\n",
    "# Load all PDFs from data directory\n",
    "loader = PyPDFDirectoryLoader(DATA_DIR)\n",
    "raw_documents = loader.load()\n",
    "print(f\"Loaded {len(raw_documents)} pages from PDFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a009e8e0",
   "metadata": {},
   "source": [
    "### Step 2: Merge pages into parent documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4af6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 200 parent documents (1 per PDF file)\n"
     ]
    }
   ],
   "source": [
    "# Group pages by source file\n",
    "docs_by_source = defaultdict(list)\n",
    "for doc in raw_documents:\n",
    "    source = doc.metadata.get('source', 'unknown')\n",
    "    docs_by_source[source].append(doc)\n",
    "\n",
    "# Create one parent document per PDF file\n",
    "documents = []\n",
    "for source, pages in docs_by_source.items():\n",
    "    combined_content = \"\\n\\n\".join([page.page_content for page in pages])\n",
    "    metadata = pages[0].metadata.copy()\n",
    "    metadata['total_pages'] = len(pages)\n",
    "    \n",
    "    parent_doc = Document(\n",
    "        page_content=combined_content,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    documents.append(parent_doc)\n",
    "\n",
    "print(f\"Created {len(documents)} parent documents (1 per PDF file)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25524f88",
   "metadata": {},
   "source": [
    "### Step 3: Set up embeddings and vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f4e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "CHROMA_DIR = \"../backend/chroma_db\"\n",
    "PARENT_STORE_DIR = \"../backend/parent_docs\"\n",
    "\n",
    "# Set up persistent storage with Ollama embeddings\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=OLLAMA_EMBEDDING_MODEL,\n",
    "    base_url=OLLAMA_BASE_URL\n",
    ")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"records\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=CHROMA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f7b00",
   "metadata": {},
   "source": [
    "### Step 4: Configure retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2c371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import LocalFileStore, create_kv_docstore\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "parent_store = LocalFileStore(PARENT_STORE_DIR)\n",
    "docstore = create_kv_docstore(parent_store)\n",
    "\n",
    "# Configure retriever\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac61167",
   "metadata": {},
   "source": [
    "### Step 5: Index documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "415b41f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting indexing...\n",
      "Indexed 200 parent documents\n"
     ]
    }
   ],
   "source": [
    "# Index all documents\n",
    "print(\"Starting indexing...\")\n",
    "retriever.add_documents(documents, ids=None)\n",
    "print(f\"Indexed {len(documents)} parent documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77984f0",
   "metadata": {},
   "source": [
    "### Step 6: Verify indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3280e957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1598 child chunks from 200 parent documents\n",
      "Indexing complete!\n"
     ]
    }
   ],
   "source": [
    "# Check what got indexed\n",
    "num_children = len(vectorstore.get()['ids'])\n",
    "print(f\"Created {num_children} child chunks from {len(documents)} parent documents\")\n",
    "print(\"Indexing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffec4829",
   "metadata": {},
   "source": [
    "## Phase 2: Retrieval (Query Existing Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b53c6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing index for retrieval...\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Configuration\n",
    "CHROMA_DIR = \"../backend/chroma_db\"\n",
    "PARENT_STORE_DIR = \"../backend/parent_docs\"\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "OLLAMA_EMBEDDING_MODEL = \"mxbai-embed-large:335m\"\n",
    "\n",
    "print(\"Loading existing index for retrieval...\")\n",
    "\n",
    "# Connect to existing persistent stores\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=OLLAMA_EMBEDDING_MODEL,\n",
    "    base_url=OLLAMA_BASE_URL\n",
    ")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"records\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=CHROMA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e4a9e",
   "metadata": {},
   "source": [
    "### Step 2: Configure retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b3ace3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain.storage import LocalFileStore, create_kv_docstore\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "parent_store = LocalFileStore(PARENT_STORE_DIR)\n",
    "docstore = create_kv_docstore(parent_store)\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=None\n",
    ")\n",
    "\n",
    "print(\"Index loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab8a4c",
   "metadata": {},
   "source": [
    "### Step 3: Query and retrieve document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a9bdbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'Who is arjun chowdhury?'\n",
      "Retrieved 1 document\n",
      "Source File: ..\\Data\\Data\\IR_Case_2.pdf\n",
      "Total Pages: 2\n",
      "Total Content Size: 2417 characters\n",
      "Document content retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is arjun chowdhury?\"\n",
    "print(f\"Query: '{query}'\")\n",
    "\n",
    "try:\n",
    "    results = retriever.invoke(query)\n",
    "    results = results[:1]\n",
    "\n",
    "    if results:\n",
    "        print(f\"Retrieved {len(results)} document\")\n",
    "\n",
    "        doc = results[0]\n",
    "        print(f\"Source File: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        print(f\"Total Pages: {doc.metadata.get('total_pages', 'Unknown')}\")\n",
    "        print(f\"Total Content Size: {len(doc.page_content)} characters\")\n",
    "        print(\"Document content retrieved successfully\")\n",
    "    else:\n",
    "        print(\"No relevant documents found for the query.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during retrieval: {e}\")\n",
    "    print(\"Check that Ollama is running and accessible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ea1dd",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "\n",
    "1. **First time setup**: Run Phase 1 cells (Steps 1-6) to index your documents\n",
    "2. **For queries**: Run Phase 2 cells (Steps 1-3) and modify the query variable\n",
    "3. **Re-indexing**: Only run Phase 1 again if you add new documents\n",
    "\n",
    "This setup ensures:\n",
    "- Documents are processed only once\n",
    "- Fast query responses\n",
    "- Persistent storage across sessions\n",
    "- Parent-child document retrieval for better context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
